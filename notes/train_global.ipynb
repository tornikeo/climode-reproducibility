{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/climode-reproducibility/climode/ClimODE\n"
     ]
    }
   ],
   "source": [
    "# %cd ./climode/ClimODE/\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "import warnings\n",
    "from tqdm.cli import tqdm\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as Fin\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib \n",
    "from torchdiffeq import odeint as odeint\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.empty_cache() \n",
    "import torch.optim as optim\n",
    "import random\n",
    "import logging\n",
    "logging.propagate = False \n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "# from model_function import *\n",
    "# from model_utils import *\n",
    "from utils import set_seed\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(solver='euler', atol=0.005, rtol=0.005, step_size=None, niters=300, scale=0, batch_size=6, spectral=0, lr=0.0005, weight_decay=1e-05)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "#data_path = {'z500':str(cwd) + '/era5_data/geopotential_500/*.nc','t850':str(cwd) + '/era5_data/temperature_850/*.nc'}\n",
    "SOLVERS = [\"dopri8\",\"dopri5\", \"bdf\", \"rk4\", \"midpoint\", 'adams', 'explicit_adams', 'fixed_adams',\"adaptive_heun\",\"euler\"]\n",
    "parser = argparse.ArgumentParser('ClimODE')\n",
    "\n",
    "parser.add_argument('--solver', type=str, default=\"euler\", choices=SOLVERS)\n",
    "parser.add_argument('--atol', type=float, default=5e-3)\n",
    "parser.add_argument('--rtol', type=float, default=5e-3)\n",
    "parser.add_argument(\"--step_size\", type=float, default=None, help=\"Optional fixed step size.\")\n",
    "parser.add_argument('--niters', type=int, default=300)\n",
    "parser.add_argument('--scale', type=int, default=0)\n",
    "parser.add_argument('--batch_size', type=int, default=6)\n",
    "parser.add_argument('--spectral', type=int, default=0,choices=[0,1])\n",
    "parser.add_argument('--lr', type=float, default=0.0005)\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-5)\n",
    "\n",
    "\n",
    "args = parser.parse_args('--scale 0 --batch_size 6 --spectral 0 --solver euler'.split())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_scale= slice('2006','2016')\n",
    "val_time_scale = slice('2016','2016')\n",
    "test_time_scale = slice('2017','2018')\n",
    "\n",
    "paths_to_data = [str(cwd) + '/era5_data/geopotential_500/*.nc',\n",
    "                 str(cwd) + '/era5_data/temperature_850/*.nc',\n",
    "                 str(cwd) + '/era5_data/2m_temperature/*.nc',\n",
    "                 str(cwd) + '/era5_data/10m_u_component_of_wind/*.nc',\n",
    "                 str(cwd) + '/era5_data/10m_v_component_of_wind/*.nc']\n",
    "const_info_path = [str(cwd) +  '/era5_data/constants/constants/constants_5.625deg.nc']\n",
    "levels = [\"z\",\"t\",\"t2m\",\"u10\",\"v10\"]\n",
    "paths_to_data = paths_to_data[0:5]\n",
    "levels = levels[0:5]\n",
    "assert len(paths_to_data) == len(levels), \"Paths to different type of data must be same as number of types of observations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "def get_batched(train_times,data_train_final,lev):\n",
    "    for idx,year in enumerate(train_times):\n",
    "        data_per_year = data_train_final.sel(time=slice(str(year),str(year))).load()\n",
    "        data_values = data_per_year[lev].values\n",
    "        if idx ==0:\n",
    "            train_data = torch.from_numpy(data_values).reshape(-1,1,1,data_values.shape[-2],data_values.shape[-1])\n",
    "            if year%4==0: train_data = torch.cat((train_data[:236],train_data[240:])) #skipping 29 feb in leap year\n",
    "        else:\n",
    "            mid_data = torch.from_numpy(data_values).reshape(-1,1,1,data_values.shape[-2],data_values.shape[-1])\n",
    "            if year%4==0: mid_data = torch.cat((mid_data[:236],mid_data[240:]))#skipping 29 feb in leap year\n",
    "            train_data = torch.cat([train_data,mid_data],dim=1)\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "def get_train_test_data_without_scales_batched(data_path,train_time_scale,val_time_scale,test_time_scale,lev,spectral):\n",
    "    data = xr.open_mfdataset(data_path, combine='by_coords')\n",
    "    #data = data.isel(lat=slice(None, None, -1))\n",
    "    if lev in [\"v\",\"u\",\"r\",\"q\",\"tisr\"]:\n",
    "        data = data.sel(level=500)\n",
    "    data = data.resample(time=\"6H\").nearest(tolerance=\"1H\") # Setting data to be 6-hour cycles\n",
    "    data_train = data.sel(time=train_time_scale).load()\n",
    "    data_val = data.sel(time=val_time_scale).load()\n",
    "    data_test = data.sel(time=test_time_scale).load()\n",
    "    data_global = data.sel(time=slice('2006','2018')).load()\n",
    "\n",
    "    max_val = data_global.max()[lev].values.tolist()\n",
    "    min_val = data_global.min()[lev].values.tolist()\n",
    "\n",
    "\n",
    "    data_train_final = (data_train - min_val)/ (max_val - min_val)\n",
    "    data_val_final = (data_val - min_val)/ (max_val - min_val)\n",
    "    data_test_final = (data_test - min_val)/ (max_val - min_val)\n",
    "\n",
    "    time_vals = data_test_final.time.values\n",
    "    train_times = [i for i in range(2006,2016)]\n",
    "    test_times = [2017,2018]\n",
    "    val_times = [2016]\n",
    "\n",
    "    train_data = get_batched(train_times,data_train_final,lev)\n",
    "    test_data = get_batched(test_times,data_test_final,lev)\n",
    "    val_data = get_batched(val_times,data_val_final,lev)\n",
    "\n",
    "    t = [i for i in range(365*4)]\n",
    "    time_steps = torch.tensor(t).view(-1,1)\n",
    "    return train_data,val_data,test_data,time_steps,data.lat.values,data.lon.values,max_val,min_val,time_vals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/xarray/groupers.py:403: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  self.index_grouper = pd.Grouper(\n",
      "/opt/conda/lib/python3.10/site-packages/xarray/core/indexes.py:561: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  flat_indexer = index.get_indexer(flat_labels, method=method, tolerance=tolerance)\n",
      "/opt/conda/lib/python3.10/site-packages/xarray/groupers.py:403: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  self.index_grouper = pd.Grouper(\n",
      "/opt/conda/lib/python3.10/site-packages/xarray/core/indexes.py:561: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  flat_indexer = index.get_indexer(flat_labels, method=method, tolerance=tolerance)\n",
      "/opt/conda/lib/python3.10/site-packages/xarray/groupers.py:403: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  self.index_grouper = pd.Grouper(\n",
      "/opt/conda/lib/python3.10/site-packages/xarray/core/indexes.py:561: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  flat_indexer = index.get_indexer(flat_labels, method=method, tolerance=tolerance)\n",
      "/opt/conda/lib/python3.10/site-packages/xarray/groupers.py:403: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  self.index_grouper = pd.Grouper(\n",
      "/opt/conda/lib/python3.10/site-packages/xarray/core/indexes.py:561: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  flat_indexer = index.get_indexer(flat_labels, method=method, tolerance=tolerance)\n",
      "/opt/conda/lib/python3.10/site-packages/xarray/groupers.py:403: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  self.index_grouper = pd.Grouper(\n",
      "/opt/conda/lib/python3.10/site-packages/xarray/core/indexes.py:561: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  flat_indexer = index.get_indexer(flat_labels, method=method, tolerance=tolerance)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data 1460\n",
      "Length of validation data 1460\n",
      "Length of testing data 1460\n"
     ]
    }
   ],
   "source": [
    "Final_train_data = 0\n",
    "Final_val_data = 0\n",
    "Final_test_data = 0\n",
    "max_lev = []\n",
    "min_lev = []\n",
    "\n",
    "for idx,data in enumerate(paths_to_data):\n",
    "    Train_data,Val_data,Test_data,time_steps,lat,lon,mean,std,time_stamp = \\\n",
    "        get_train_test_data_without_scales_batched(data,train_time_scale,val_time_scale,test_time_scale,levels[idx],args.spectral)  \n",
    "    max_lev.append(mean)\n",
    "    min_lev.append(std)\n",
    "    if idx==0: \n",
    "        Final_train_data = Train_data\n",
    "        Final_val_data = Val_data\n",
    "        Final_test_data = Test_data\n",
    "    else:\n",
    "        Final_train_data = torch.cat([Final_train_data,Train_data],dim=2)\n",
    "        Final_val_data = torch.cat([Final_val_data,Val_data],dim=2)\n",
    "        Final_test_data = torch.cat([Final_test_data,Test_data],dim=2)\n",
    "\n",
    "\n",
    "print(\"Length of training data\",len(Final_train_data))\n",
    "print(\"Length of validation data\",len(Final_val_data))\n",
    "print(\"Length of testing data\",len(Final_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_function import add_constant_info, Climate_encoder_free_uncertain\n",
    "from utils import count_parameters\n",
    "\n",
    "const_channels_info,lat_map,lon_map = add_constant_info(const_info_path)\n",
    "H,W = Train_data.shape[3],Train_data.shape[4]\n",
    "Train_loader = DataLoader(Final_train_data[2:],\n",
    "                          batch_size=args.batch_size,shuffle=False,pin_memory=False)\n",
    "Val_loader = DataLoader(Final_val_data[2:],\n",
    "                        batch_size=args.batch_size,shuffle=False,pin_memory=False)\n",
    "Test_loader = DataLoader(Final_test_data[2:],\n",
    "                         batch_size=args.batch_size,shuffle=False,pin_memory=False)\n",
    "time_loader = DataLoader(time_steps[2:],\n",
    "                         batch_size=args.batch_size,shuffle=False,pin_memory=False)\n",
    "time_idx_steps = torch.tensor([i for i in range(365*4)]).view(-1,1)\n",
    "time_idx = DataLoader(time_idx_steps[2:],batch_size=args.batch_size,shuffle=False,pin_memory=False)\n",
    "#Model declaration\n",
    "num_years = len(range(2006,2016))\n",
    "model = Climate_encoder_free_uncertain(len(paths_to_data),2,out_types=len(paths_to_data),method=args.solver,use_att=True,use_err=True,use_pos=False).to(device)\n",
    "#model.apply(weights_init_uniform_rule)\n",
    "\n",
    "param = count_parameters(model)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 300)\n",
    "\n",
    "best_loss = float('inf')\n",
    "train_best_loss = float('inf')\n",
    "best_epoch = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## DETECTED kernel.npy from previous run, will load from disk instead of regen. \n",
      "## DETECTED test_10year_2day_mm_vel.npy from previous run, will load from disk instead of regen\n",
      "############################ Velocity loaded, Model starts to train #########################\n",
      "####################### Total Parameters 2752099 ################################\n"
     ]
    }
   ],
   "source": [
    "from utils import load_velocity, fit_velocity, get_gauss_kernel\n",
    "from model_function import Optim_velocity\n",
    "\n",
    "if not Path(str(cwd) +\"/kernel.npy\").exists():\n",
    "    get_gauss_kernel((32,64),lat,lon)\n",
    "else:\n",
    "    print(\"## DETECTED kernel.npy from previous run, will load from disk instead of regen. \")\n",
    "\n",
    "kernel = torch.from_numpy(np.load(str(cwd) +\"/kernel.npy\"))\n",
    "#breakpoint()\n",
    "if not Path('test_10year_2day_mm_vel.npy').exists():\n",
    "    print(\"Fitting velocity...\")\n",
    "    fit_velocity(time_idx,time_loader,Final_train_data,Train_loader,torch.device('cuda'),num_years,paths_to_data,args.scale,H,W,types='train_10year_2day_mm',vel_model=Optim_velocity,kernel=kernel,lat=lat,lon=lon)\n",
    "    fit_velocity(time_idx,time_loader,Final_val_data,Val_loader,torch.device('cuda'),1,paths_to_data,args.scale,H,W,types='val_10year_2day_mm',vel_model=Optim_velocity,kernel=kernel,lat=lat,lon=lon)\n",
    "    fit_velocity(time_idx,time_loader,Final_test_data,Test_loader,torch.device('cuda'),2,paths_to_data,args.scale,H,W,types='test_10year_2day_mm',vel_model=Optim_velocity,kernel=kernel,lat=lat,lon=lon)\n",
    "else:\n",
    "    print(\"## DETECTED test_10year_2day_mm_vel.npy from previous run, will load from disk instead of regen\")\n",
    "    \n",
    "vel_train,vel_val = load_velocity(['train_10year_2day_mm','val_10year_2day_mm'])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"############################ Velocity loaded, Model starts to train #########################\")\n",
    "# print(model)\n",
    "print(\"####################### Total Parameters\",param ,\"################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 2.8e+06 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model has {param:.1e} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Epoch 0 of 300 #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|\u001b[32m          \u001b[0m| 0/243 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  11%|\u001b[32mâ–ˆ         \u001b[0m| 26/243 [00:24<03:27,  1.05it/s, loss=18.3]"
     ]
    }
   ],
   "source": [
    "from utils import nll\n",
    "\n",
    "for epoch in range(args.niters):\n",
    "    print(f\"##### Epoch {epoch} of {args.niters} #####\")\n",
    "    total_train_loss = 0\n",
    "    val_loss = 0\n",
    "    test_loss = 0\n",
    "    #RMSD = []\n",
    "    #breakpoint()\n",
    "    if epoch == 0:\n",
    "        var_coeff = 0.001\n",
    "    else:\n",
    "        var_coeff = 2*scheduler.get_last_lr()[0]\n",
    "        \n",
    "    _total = min(len(time_loader), len(Train_loader))\n",
    "    pbar = tqdm(enumerate(zip(time_loader,Train_loader)), \n",
    "                                         total=_total, \n",
    "                                         colour='green', desc='train')\n",
    "    for entry,(time_steps,batch) in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        data = batch[0].to(device).view(num_years,1,len(paths_to_data)*(args.scale+1),H,W)\n",
    "        past_sample = vel_train[entry].view(num_years,2*len(paths_to_data)*(args.scale+1),H,W).to(device)\n",
    "        model.update_param([past_sample,const_channels_info.to(device),lat_map.to(device),lon_map.to(device)])\n",
    "        t = time_steps.float().to(device).flatten()\n",
    "        mean,std,_ = model(t,data)\n",
    "        loss = nll(mean,std,batch.float().to(device),lat,var_coeff)\n",
    "        l2_lambda = 0.001\n",
    "        l2_norm = sum(p.pow(2.0).sum()\n",
    "                for p in model.parameters())\n",
    "        loss = loss + l2_lambda * l2_norm\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "        # print(\"Loss for batch is \",loss.item())\n",
    "        pbar.set_postfix({\"loss\":loss.item()})\n",
    "        if torch.isnan(loss) : \n",
    "            print(\"Quitting due to Nan loss\")\n",
    "            quit()\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "        \n",
    "\n",
    "    lr_val = scheduler.get_last_lr()[0]\n",
    "    scheduler.step()\n",
    "    print(\"|Iter \",epoch,\" | Total Train Loss \", total_train_loss,\"|\")\n",
    "  \n",
    "    for entry,(time_steps,batch) in enumerate(zip(tqdm(time_loader, colour='blue', desc='test'),Val_loader)):\n",
    "        data = batch[0].to(device).view(1,1,len(paths_to_data)*(args.scale+1),H,W)\n",
    "        past_sample = vel_val[entry].view(1,2*len(paths_to_data)*(args.scale+1),H,W).to(device)\n",
    "        model.update_param([past_sample,const_channels_info.to(device),lat_map.to(device),lon_map.to(device)])\n",
    "        t = time_steps.float().to(device).flatten()\n",
    "        mean,std,_ = model(t,data)\n",
    "        loss = nll(mean,std,batch.float().to(device),lat,var_coeff)\n",
    "        if torch.isnan(loss) : \n",
    "            print(\"Quitting due to Nan loss\")\n",
    "            quit()\n",
    "        print(\"Val Loss for batch is \",loss.item())\n",
    "        val_loss = val_loss + loss.item()\n",
    "\n",
    "    print(\"|Iter \",epoch,\" | Total Val Loss \", val_loss,\"|\")\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model, str(cwd) + \"/Models/\" + \"ClimODE_global_\"+args.solver+\"_\"+str(args.spectral)+\"_model_\" + str(epoch) + \".pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
