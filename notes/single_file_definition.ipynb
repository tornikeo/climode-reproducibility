{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Namespace(solver='euler', atol=0.005, rtol=0.005, step_size=None, niters=300, scale=0, batch_size=6, spectral=0, lr=0.0005, weight_decay=1e-05)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import datasets\n",
    "import warnings\n",
    "from tqdm.cli import tqdm\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as Fin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from torchdiffeq import odeint as odeint\n",
    "import matplotlib\n",
    "import argparse\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "# data_path = {'z500':str(cwd) + '/era5_data/geopotential_500/*.nc','t850':str(cwd) + '/era5_data/temperature_850/*.nc'}\n",
    "SOLVERS = [\n",
    "    \"dopri8\",\n",
    "    \"dopri5\",\n",
    "    \"bdf\",\n",
    "    \"rk4\",\n",
    "    \"midpoint\",\n",
    "    \"adams\",\n",
    "    \"explicit_adams\",\n",
    "    \"fixed_adams\",\n",
    "    \"adaptive_heun\",\n",
    "    \"euler\",\n",
    "]\n",
    "parser = argparse.ArgumentParser(\"ClimODE\")\n",
    "\n",
    "parser.add_argument(\"--solver\", type=str, default=\"euler\", choices=SOLVERS)\n",
    "parser.add_argument(\"--atol\", type=float, default=5e-3)\n",
    "parser.add_argument(\"--rtol\", type=float, default=5e-3)\n",
    "parser.add_argument(\n",
    "    \"--step_size\", type=float, default=None, help=\"Optional fixed step size.\"\n",
    ")\n",
    "parser.add_argument(\"--niters\", type=int, default=300)\n",
    "parser.add_argument(\"--scale\", type=int, default=0)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=6)\n",
    "parser.add_argument(\"--spectral\", type=int, default=0, choices=[0, 1])\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0005)\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=1e-5)\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"--scale 0 --batch_size 6 --spectral 0 --solver euler\".split())\n",
    "assert torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\")\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_scale = slice(\"2006\", \"2016\")\n",
    "val_time_scale = slice(\"2016\", \"2016\")\n",
    "test_time_scale = slice(\"2017\", \"2018\")\n",
    "paths_to_data = [\n",
    "    \"era5_data/geopotential_500/*.nc\",\n",
    "    \"era5_data/temperature_850/*.nc\",\n",
    "    \"era5_data/2m_temperature/*.nc\",\n",
    "    \"era5_data/10m_u_component_of_wind/*.nc\",\n",
    "    \"era5_data/10m_v_component_of_wind/*.nc\",\n",
    "]\n",
    "const_info_path = [\"era5_data/constants/constants/constants_5.625deg.nc\"]\n",
    "levels = [\"z\", \"t\", \"t2m\", \"u10\", \"v10\"]\n",
    "\n",
    "assert len(paths_to_data) == len(\n",
    "    levels\n",
    "), \"Paths to different type of data must be same as number of types of observations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data: 100%|██████████| 5/5 [00:20<00:00,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, val, test data shapes:\n",
      "torch.Size([1460, 10, 5, 32, 64]) torch.Size([1460, 2, 5, 32, 64]) torch.Size([1460, 1, 5, 32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "\n",
    "def get_batched(train_times, data_train_final, lev):\n",
    "    for idx, year in enumerate(train_times):\n",
    "        data_per_year = data_train_final.sel(time=slice(str(year), str(year))).load()\n",
    "        data_values = data_per_year[lev].values\n",
    "        if idx == 0:\n",
    "            train_data = torch.from_numpy(data_values).reshape(\n",
    "                -1, 1, 1, data_values.shape[-2], data_values.shape[-1]\n",
    "            )\n",
    "            if year % 4 == 0:\n",
    "                train_data = torch.cat(\n",
    "                    (train_data[:236], train_data[240:])\n",
    "                )  # skipping 29 feb in leap year\n",
    "        else:\n",
    "            mid_data = torch.from_numpy(data_values).reshape(\n",
    "                -1, 1, 1, data_values.shape[-2], data_values.shape[-1]\n",
    "            )\n",
    "            if year % 4 == 0:\n",
    "                mid_data = torch.cat(\n",
    "                    (mid_data[:236], mid_data[240:])\n",
    "                )  # skipping 29 feb in leap year\n",
    "            train_data = torch.cat([train_data, mid_data], dim=1)\n",
    "\n",
    "    return train_data\n",
    "\n",
    "\n",
    "def get_train_test_data_without_scales_batched(\n",
    "    data_path, train_time_scale, val_time_scale, test_time_scale, lev, spectral\n",
    "):\n",
    "    data = xr.open_mfdataset(data_path, combine=\"by_coords\")\n",
    "    # data = data.isel(lat=slice(None, None, -1))\n",
    "    if lev in [\"v\", \"u\", \"r\", \"q\", \"tisr\"]:\n",
    "        data = data.sel(level=500)\n",
    "    data = data.resample(time=\"6h\").nearest(\n",
    "        tolerance=\"1h\"\n",
    "    )  # Setting data to be 6-hour cycles\n",
    "    data_train = data.sel(time=train_time_scale).load()\n",
    "    data_val = data.sel(time=val_time_scale).load()\n",
    "    data_test = data.sel(time=test_time_scale).load()\n",
    "    data_global = data.sel(time=slice(\"2006\", \"2018\")).load()\n",
    "\n",
    "    max_val = data_global.max()[lev].values.tolist()\n",
    "    min_val = data_global.min()[lev].values.tolist()\n",
    "\n",
    "    data_train_final = (data_train - min_val) / (max_val - min_val)\n",
    "    data_val_final = (data_val - min_val) / (max_val - min_val)\n",
    "    data_test_final = (data_test - min_val) / (max_val - min_val)\n",
    "\n",
    "    time_vals = data_test_final.time.values\n",
    "    train_times = [i for i in range(2006, 2016)]\n",
    "    test_times = [2017, 2018]\n",
    "    val_times = [2016]\n",
    "\n",
    "    train_data = get_batched(train_times, data_train_final, lev)\n",
    "    test_data = get_batched(test_times, data_test_final, lev)\n",
    "    val_data = get_batched(val_times, data_val_final, lev)\n",
    "\n",
    "    t = [i for i in range(365 * 4)]\n",
    "    time_steps = torch.tensor(t).view(-1, 1)\n",
    "    return (\n",
    "        train_data,\n",
    "        val_data,\n",
    "        test_data,\n",
    "        time_steps,\n",
    "        data.lat.values,\n",
    "        data.lon.values,\n",
    "        max_val,\n",
    "        min_val,\n",
    "        time_vals,\n",
    "    )\n",
    "\n",
    "\n",
    "Final_train_data = 0\n",
    "Final_val_data = 0\n",
    "Final_test_data = 0\n",
    "max_lev = []\n",
    "min_lev = []\n",
    "\n",
    "for idx, data in enumerate(tqdm(paths_to_data, desc=\"reading data\")):\n",
    "    Train_data, Val_data, Test_data, time_steps, lat, lon, mean, std, time_stamp = (\n",
    "        get_train_test_data_without_scales_batched(\n",
    "            data,\n",
    "            train_time_scale,\n",
    "            val_time_scale,\n",
    "            test_time_scale,\n",
    "            levels[idx],\n",
    "            args.spectral,\n",
    "        )\n",
    "    )\n",
    "    max_lev.append(mean)\n",
    "    min_lev.append(std)\n",
    "    if idx == 0:\n",
    "        Final_train_data = Train_data\n",
    "        Final_val_data = Val_data\n",
    "        Final_test_data = Test_data\n",
    "    else:\n",
    "        Final_train_data = torch.cat([Final_train_data, Train_data], dim=2)\n",
    "        Final_val_data = torch.cat([Final_val_data, Val_data], dim=2)\n",
    "        Final_test_data = torch.cat([Final_test_data, Test_data], dim=2)\n",
    "\n",
    "print(\"train, val, test data shapes:\")\n",
    "print(Final_train_data.shape, Final_test_data.shape, Final_val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_constant_info(path):\n",
    "    data = xr.open_mfdataset(path, combine=\"by_coords\")\n",
    "    for idx, var in enumerate([\"orography\", \"lsm\"]):\n",
    "        var_value = torch.from_numpy(data[var].values).view(1, 1, 32, 64)\n",
    "        if idx == 0:\n",
    "            final_var = var_value\n",
    "        else:\n",
    "            final_var = torch.cat([final_var, var_value], dim=1)\n",
    "\n",
    "    return (\n",
    "        final_var,\n",
    "        torch.from_numpy(data[\"lat2d\"].values),\n",
    "        torch.from_numpy(data[\"lon2d\"].values),\n",
    "    )\n",
    "\n",
    "\n",
    "const_channels_info, lat_map, lon_map = add_constant_info(const_info_path)\n",
    "H, W = Train_data.shape[3], Train_data.shape[4]\n",
    "Train_loader = DataLoader(\n",
    "    Final_train_data[2:], batch_size=args.batch_size, shuffle=False, pin_memory=False\n",
    ")\n",
    "Val_loader = DataLoader(\n",
    "    Final_val_data[2:], batch_size=args.batch_size, shuffle=False, pin_memory=False\n",
    ")\n",
    "Test_loader = DataLoader(\n",
    "    Final_test_data[2:], batch_size=args.batch_size, shuffle=False, pin_memory=False\n",
    ")\n",
    "time_loader = DataLoader(\n",
    "    time_steps[2:], batch_size=args.batch_size, shuffle=False, pin_memory=False\n",
    ")\n",
    "time_idx_steps = torch.tensor([i for i in range(365 * 4)]).view(-1, 1)\n",
    "time_idx = DataLoader(\n",
    "    time_idx_steps[2:], batch_size=args.batch_size, shuffle=False, pin_memory=False\n",
    ")\n",
    "\n",
    "# Model declaration\n",
    "num_years = len(range(2006, 2016))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1460, 10, 5, 32, 64]),\n",
       " torch.Size([1460, 2, 5, 32, 64]),\n",
       " torch.Size([1460, 1, 5, 32, 64]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Climate_encoder_free_uncertain(\n",
    "    len(paths_to_data),\n",
    "    2,\n",
    "    out_types=len(paths_to_data),\n",
    "    method=args.solver,\n",
    "    use_att=True,\n",
    "    use_err=True,\n",
    "    use_pos=False,\n",
    ").to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
