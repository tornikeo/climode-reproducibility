{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm.cli import tqdm\n",
    "import numpy as np\n",
    "from torchdiffeq import odeint\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim\n",
    "import xarray as xr\n",
    "\n",
    "import fire\n",
    "\n",
    "from climode.utils import fit_velocity, get_gauss_kernel\n",
    "from climode.model_function import Optim_velocity, Climate_encoder_free_uncertain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from climode.utils import evaluation_crps_mm, evaluation_acc_mm, evaluation_rmsd_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_batched(train_times, data_train_final, lev):\n",
    "    for idx, year in enumerate(train_times):\n",
    "        data_per_year = data_train_final.sel(time=slice(str(year), str(year))).load()\n",
    "        data_values = data_per_year[lev].values\n",
    "        if idx == 0:\n",
    "            train_data = torch.from_numpy(data_values).reshape(\n",
    "                -1, 1, 1, data_values.shape[-2], data_values.shape[-1]\n",
    "            )\n",
    "            if year % 4 == 0:\n",
    "                train_data = torch.cat(\n",
    "                    (train_data[:236], train_data[240:])\n",
    "                )  # skipping 29 feb in leap year\n",
    "        else:\n",
    "            mid_data = torch.from_numpy(data_values).reshape(\n",
    "                -1, 1, 1, data_values.shape[-2], data_values.shape[-1]\n",
    "            )\n",
    "            if year % 4 == 0:\n",
    "                mid_data = torch.cat(\n",
    "                    (mid_data[:236], mid_data[240:])\n",
    "                )  # skipping 29 feb in leap year\n",
    "            train_data = torch.cat([train_data, mid_data], dim=1)\n",
    "\n",
    "    return train_data\n",
    "\n",
    "\n",
    "def get_train_test_data_without_scales_batched(\n",
    "    data_path, train_time_scale, val_time_scale, test_time_scale, lev, spectral\n",
    "):\n",
    "    data = xr.open_mfdataset(data_path, combine=\"by_coords\")\n",
    "    # data = data.isel(lat=slice(None, None, -1))\n",
    "    if lev in [\"v\", \"u\", \"r\", \"q\", \"tisr\"]:\n",
    "        data = data.sel(level=500)\n",
    "    data = data.resample(time=\"6h\").nearest(\n",
    "        tolerance=\"1h\"\n",
    "    )  # Setting data to be 6-hour cycles\n",
    "    data_train = data.sel(time=train_time_scale).load()\n",
    "    data_val = data.sel(time=val_time_scale).load()\n",
    "    data_test = data.sel(time=test_time_scale).load()\n",
    "    data_global = data.sel(time=slice(\"2006\", \"2018\")).load()\n",
    "\n",
    "    max_val = data_global.max()[lev].values.tolist()\n",
    "    min_val = data_global.min()[lev].values.tolist()\n",
    "\n",
    "    data_train_final = (data_train - min_val) / (max_val - min_val)\n",
    "    data_val_final = (data_val - min_val) / (max_val - min_val)\n",
    "    data_test_final = (data_test - min_val) / (max_val - min_val)\n",
    "\n",
    "    time_vals = data_test_final.time.values\n",
    "    train_times = [i for i in range(2006, 2016)]\n",
    "    test_times = [2017, 2018]\n",
    "    val_times = [2016]\n",
    "\n",
    "    train_data = get_batched(train_times, data_train_final, lev)\n",
    "    test_data = get_batched(test_times, data_test_final, lev)\n",
    "    val_data = get_batched(val_times, data_val_final, lev)\n",
    "\n",
    "    t = [i for i in range(365 * 4)]\n",
    "    time_steps = torch.tensor(t).view(-1, 1)\n",
    "    return (\n",
    "        train_data,\n",
    "        val_data,\n",
    "        test_data,\n",
    "        time_steps,\n",
    "        data.lat.values,\n",
    "        data.lon.values,\n",
    "        max_val,\n",
    "        min_val,\n",
    "        time_vals,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_velocity(types):\n",
    "    vel = []\n",
    "    for file in types:\n",
    "        vel.append(np.load(f\"{file}_vel.npy\"))\n",
    "    return (torch.from_numpy(v) for v in vel)\n",
    "\n",
    "\n",
    "def add_constant_info(path):\n",
    "    data = xr.open_mfdataset(path, combine=\"by_coords\")\n",
    "    for idx, var in enumerate([\"orography\", \"lsm\"]):\n",
    "        var_value = torch.from_numpy(data[var].values).view(1, 1, 32, 64)\n",
    "        if idx == 0:\n",
    "            final_var = var_value\n",
    "        else:\n",
    "            final_var = torch.cat([final_var, var_value], dim=1)\n",
    "\n",
    "    return (\n",
    "        final_var,\n",
    "        torch.from_numpy(data[\"lat2d\"].values),\n",
    "        torch.from_numpy(data[\"lon2d\"].values),\n",
    "    )\n",
    "\n",
    "\n",
    "def nll(mean, std, truth, lat, var_coeff):\n",
    "    normal_lkl = torch.distributions.normal.Normal(mean, 1e-3 + std)\n",
    "    lkl = -normal_lkl.log_prob(truth)\n",
    "    loss_val = lkl.mean() + var_coeff * (std**2).sum()\n",
    "    return loss_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path='checkpoints/ClimODE_global_euler_0_model_11_-425.2301845550537.pt'\n",
    "solver=\"euler\"\n",
    "atol=5e-3\n",
    "rtol=5e-3\n",
    "step_size=None\n",
    "niters=100\n",
    "scale=0\n",
    "batch_size=6\n",
    "spectral=0\n",
    "lr=0.0005\n",
    "weight_decay=1e-5\n",
    "dryrun=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Running with solver=euler, atol=0.005, rtol=0.005,step_size=None, niters=100, scale=0,batch_size=6, spectral=0, lr=0.0005,weight_decay=1e-05\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data: 100%|██████████| 5/5 [00:12<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, val, test data shapes:\n",
      "torch.Size([1460, 10, 5, 32, 64]) torch.Size([1460, 1, 5, 32, 64]) torch.Size([1460, 2, 5, 32, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "SOLVERS = [\n",
    "    \"dopri8\",\n",
    "    \"dopri5\",\n",
    "    \"bdf\",\n",
    "    \"rk4\",\n",
    "    \"midpoint\",\n",
    "    \"adams\",\n",
    "    \"explicit_adams\",\n",
    "    \"fixed_adams\",\n",
    "    \"adaptive_heun\",\n",
    "    \"euler\",\n",
    "]\n",
    "\n",
    "if solver not in SOLVERS:\n",
    "    raise ValueError(f\"Invalid solver: {solver}. Choose from {SOLVERS}.\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\n",
    "    f\"Running with solver={solver}, atol={atol}, rtol={rtol},\"\n",
    "    f\"step_size={step_size}, niters={niters}, scale={scale},\"\n",
    "    f\"batch_size={batch_size}, spectral={spectral}, lr={lr},\"\n",
    "    f\"weight_decay={weight_decay}\",\n",
    ")\n",
    "print(\"=\" * 50)\n",
    "if dryrun:\n",
    "    print(\"=\" * 25, \"DRYRUN ACTIVE WILL BREAK EARLY\", \"=\" * 25)\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_time_scale = slice(\"2006\", \"2016\")\n",
    "val_time_scale = slice(\"2016\", \"2016\")\n",
    "test_time_scale = slice(\"2017\", \"2018\")\n",
    "paths_to_data = [\n",
    "    \"era5_data/geopotential_500/*.nc\",\n",
    "    \"era5_data/temperature_850/*.nc\",\n",
    "    \"era5_data/2m_temperature/*.nc\",\n",
    "    \"era5_data/10m_u_component_of_wind/*.nc\",\n",
    "    \"era5_data/10m_v_component_of_wind/*.nc\",\n",
    "]\n",
    "const_info_path = [\"era5_data/constants/constants/constants_5.625deg.nc\"]\n",
    "levels = [\"z\", \"t\", \"t2m\", \"u10\", \"v10\"]\n",
    "\n",
    "assert len(paths_to_data) == len(\n",
    "    levels\n",
    "), \"Paths to different type of data must be same as number of types of observations\"\n",
    "\n",
    "Final_train_data = 0\n",
    "Final_val_data = 0\n",
    "Final_test_data = 0\n",
    "max_lev = []\n",
    "min_lev = []\n",
    "\n",
    "for idx, data in enumerate(tqdm(paths_to_data, desc=\"reading data\")):\n",
    "    Train_data, Val_data, Test_data, time_steps, lat, lon, mean, std, time_stamp = (\n",
    "        get_train_test_data_without_scales_batched(\n",
    "            data,\n",
    "            train_time_scale,\n",
    "            val_time_scale,\n",
    "            test_time_scale,\n",
    "            levels[idx],\n",
    "            spectral,\n",
    "        )\n",
    "    )\n",
    "    max_lev.append(mean)\n",
    "    min_lev.append(std)\n",
    "    if idx == 0:\n",
    "        Final_train_data = Train_data\n",
    "        Final_val_data = Val_data\n",
    "        Final_test_data = Test_data\n",
    "    else:\n",
    "        Final_train_data = torch.cat([Final_train_data, Train_data], dim=2)\n",
    "        Final_val_data = torch.cat([Final_val_data, Val_data], dim=2)\n",
    "        Final_test_data = torch.cat([Final_test_data, Test_data], dim=2)\n",
    "\n",
    "print(\"train, val, test data shapes:\")\n",
    "print(\n",
    "    Final_train_data.shape,\n",
    "    Final_val_data.shape,\n",
    "    Final_test_data.shape,\n",
    ")\n",
    "\n",
    "const_channels_info, lat_map, lon_map = add_constant_info(const_info_path)\n",
    "H, W = Train_data.shape[3], Train_data.shape[4]\n",
    "Train_loader = DataLoader(\n",
    "    Final_train_data[2:],\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "Val_loader = DataLoader(\n",
    "    Final_val_data[2:],\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "Test_loader = DataLoader(Final_test_data[2:], batch_size=batch_size)\n",
    "time_loader = DataLoader(time_steps[2:], batch_size=batch_size)\n",
    "time_idx_steps = torch.tensor([i for i in range(365 * 4)]).view(-1, 1)\n",
    "time_idx = DataLoader(time_idx_steps[2:], batch_size=batch_size)\n",
    "total_time_len = len(time_steps[2:])\n",
    "total_time_steps = time_steps[2:].numpy().flatten().tolist()\n",
    "num_years = 2\n",
    "\n",
    "if not Path(\"kernel.npy\").exists():\n",
    "    get_gauss_kernel((32, 64), lat, lon)\n",
    "\n",
    "kernel = torch.from_numpy(np.load(\"kernel.npy\"))\n",
    "if not Path(\"test_10year_2day_mm_vel.npy\").exists():\n",
    "    print(\"Fitting velocity...\")\n",
    "    fit_velocity(\n",
    "        time_idx,\n",
    "        time_loader,\n",
    "        Final_train_data,\n",
    "        Train_loader,\n",
    "        device,\n",
    "        num_years,\n",
    "        paths_to_data,\n",
    "        scale,\n",
    "        H,\n",
    "        W,\n",
    "        types=\"train_10year_2day_mm\",\n",
    "        vel_model=Optim_velocity,\n",
    "        kernel=kernel,\n",
    "    )\n",
    "    fit_velocity(\n",
    "        time_idx,\n",
    "        time_loader,\n",
    "        Final_val_data,\n",
    "        Val_loader,\n",
    "        device,\n",
    "        1,\n",
    "        paths_to_data,\n",
    "        scale,\n",
    "        H,\n",
    "        W,\n",
    "        types=\"val_10year_2day_mm\",\n",
    "        vel_model=Optim_velocity,\n",
    "        kernel=kernel,\n",
    "    )\n",
    "    fit_velocity(\n",
    "        time_idx,\n",
    "        time_loader,\n",
    "        Final_test_data,\n",
    "        Test_loader,\n",
    "        torch.device(\"cuda\"),\n",
    "        2,\n",
    "        paths_to_data,\n",
    "        scale,\n",
    "        H,\n",
    "        W,\n",
    "        types=\"test_10year_2day_mm\",\n",
    "        vel_model=Optim_velocity,\n",
    "        kernel=kernel,\n",
    "    )\n",
    "\n",
    "# vel_train, vel_val = load_velocity([\"train_10year_2day_mm\", \"val_10year_2day_mm\"])\n",
    "# vel_train, vel_val, vel_test = load_velocity(\n",
    "#     [\"train_10year_2day_mm\", \"val_10year_2day_mm\", \"test_10year_2day_mm\"]\n",
    "# )\n",
    "vel_test = torch.from_numpy(np.load('test_10year_2day_mm_vel.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([243, 2, 2, 5, 32, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vel_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim = torch.mean(Final_test_data, dim=0)\n",
    "model = Climate_encoder_free_uncertain(\n",
    "    len(paths_to_data),\n",
    "    2,\n",
    "    out_types=len(paths_to_data),\n",
    "    method=solver,\n",
    "    use_att=True,\n",
    "    use_err=True,\n",
    "    use_pos=False,\n",
    ")\n",
    "model.load_state_dict(torch.load(checkpoint_path, \n",
    "                                 map_location=device, \n",
    "                                 weights_only=True))\n",
    "model.eval();\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test:   0%|\u001b[34m          \u001b[0m| 0/243 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|\u001b[34m██████████\u001b[0m| 243/243 [01:52<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "Lead_RMSD_arr = {\n",
    "    \"z\": [[] for _ in range(7)],\n",
    "    \"t\": [[] for _ in range(7)],\n",
    "    \"t2m\": [[] for _ in range(7)],\n",
    "    \"u10\": [[] for _ in range(7)],\n",
    "    \"v10\": [[] for _ in range(7)],\n",
    "}\n",
    "Lead_ACC = {\n",
    "    \"z\": [[] for _ in range(7)],\n",
    "    \"t\": [[] for _ in range(7)],\n",
    "    \"t2m\": [[] for _ in range(7)],\n",
    "    \"u10\": [[] for _ in range(7)],\n",
    "    \"v10\": [[] for _ in range(7)],\n",
    "}\n",
    "Lead_CRPS = {\n",
    "    \"z\": [[] for _ in range(7)],\n",
    "    \"t\": [[] for _ in range(7)],\n",
    "    \"t2m\": [[] for _ in range(7)],\n",
    "    \"u10\": [[] for _ in range(7)],\n",
    "    \"v10\": [[] for _ in range(7)],\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    vel_test = vel_test.to(device)\n",
    "    pbar = tqdm(\n",
    "        enumerate(zip(time_loader, Test_loader)),\n",
    "        total=len(time_loader),\n",
    "        colour=\"blue\",\n",
    "        desc=\"test\",\n",
    "    )\n",
    "    const_channels_info = const_channels_info.to(device)\n",
    "    lat_map = lat_map.to(device)\n",
    "    lon_map = lon_map.to(device)\n",
    "    for entry, (time_steps, batch) in pbar:\n",
    "        if dryrun and entry >= 10:\n",
    "            break\n",
    "        batch = batch.to(device)\n",
    "        time_steps = time_steps.to(device).float()\n",
    "\n",
    "        data = batch[0].view(num_years, 1, len(paths_to_data) * (scale + 1), H, W)\n",
    "        past_sample = vel_test[entry].view(\n",
    "            num_years, 2 * len(paths_to_data) * (scale + 1), H, W\n",
    "        )\n",
    "        model.update_param(\n",
    "            past_sample,\n",
    "            const_channels_info,\n",
    "            lat_map,\n",
    "            lon_map,\n",
    "        )\n",
    "        \n",
    "        mean_pred, std_pred, mean_wo_bias = model(time_steps, data)\n",
    "        mean_avg = mean_pred.view(-1, len(paths_to_data) * (scale + 1), H, W)\n",
    "        std_avg = std_pred.view(-1, len(paths_to_data) * (scale + 1), H, W)\n",
    "        for yr in range(2):\n",
    "            for t_step in range(1, len(time_steps), 1):\n",
    "                evaluate_rmsd = evaluation_rmsd_mm(\n",
    "                    mean_pred[t_step, yr, :, :, :].cpu(),\n",
    "                    batch[t_step, yr, :, :, :].cpu(),\n",
    "                    lat,\n",
    "                    lon,\n",
    "                    max_lev,\n",
    "                    min_lev,\n",
    "                    H,\n",
    "                    W,\n",
    "                    levels,\n",
    "                )\n",
    "                evaluate_acc = evaluation_acc_mm(\n",
    "                    mean_pred[t_step, yr, :, :, :].cpu(),\n",
    "                    batch[t_step, yr, :, :, :].cpu(),\n",
    "                    lat,\n",
    "                    lon,\n",
    "                    max_lev,\n",
    "                    min_lev,\n",
    "                    H,\n",
    "                    W,\n",
    "                    levels,\n",
    "                    clim[yr, :, :, :].cpu().detach().numpy(),\n",
    "                )\n",
    "                evaluate_crps = evaluation_crps_mm(\n",
    "                    mean_pred[t_step, yr, :, :, :].cpu(),\n",
    "                    batch[t_step, yr, :, :, :].cpu(),\n",
    "                    lat,\n",
    "                    lon,\n",
    "                    max_lev,\n",
    "                    min_lev,\n",
    "                    H,\n",
    "                    W,\n",
    "                    levels,\n",
    "                    std_pred[t_step, yr, :, :, :].cpu(),\n",
    "                )\n",
    "                for idx, lev in enumerate(levels):\n",
    "                    Lead_RMSD_arr[lev][t_step - 1].append(evaluate_rmsd[idx])\n",
    "                    Lead_ACC[lev][t_step - 1].append(evaluate_acc[idx])\n",
    "                    Lead_CRPS[lev][t_step - 1].append(evaluate_crps[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Time  6 hours  | Observable  z | Mean RMSD  180.05722077299518 | Std RMSD  10.659300819745676\n",
      "Lead Time  6 hours  | Observable  z | Mean ACC  0.9863559323069541 | Std ACC  0.004609814359414543\n",
      "Lead Time  6 hours  | Observable  z | Mean CRPS  0.006727392 | Std CRPS  0.0058784112\n",
      "Lead Time  6 hours  | Observable  t | Mean RMSD  1.9083082369519346 | Std RMSD  0.06581351423530034\n",
      "Lead Time  6 hours  | Observable  t | Mean ACC  0.9569917334266274 | Std ACC  0.019551153391815283\n",
      "Lead Time  6 hours  | Observable  t | Mean CRPS  0.012037009 | Std CRPS  0.010041853\n",
      "Lead Time  6 hours  | Observable  t2m | Mean RMSD  2.8707083413019885 | Std RMSD  0.24781504124568227\n",
      "Lead Time  6 hours  | Observable  t2m | Mean ACC  0.8552179511765985 | Std ACC  0.08888514329427472\n",
      "Lead Time  6 hours  | Observable  t2m | Mean CRPS  0.011013006 | Std CRPS  0.012611264\n",
      "Lead Time  6 hours  | Observable  u10 | Mean RMSD  1.8645607831116249 | Std RMSD  0.0879118119324998\n",
      "Lead Time  6 hours  | Observable  u10 | Mean ACC  0.899072439347233 | Std ACC  0.013682031619602669\n",
      "Lead Time  6 hours  | Observable  u10 | Mean CRPS  0.014776558 | Std CRPS  0.017140519\n",
      "Lead Time  6 hours  | Observable  v10 | Mean RMSD  1.9662522641608233 | Std RMSD  0.10705430389703692\n",
      "Lead Time  6 hours  | Observable  v10 | Mean ACC  0.8855092586012556 | Std ACC  0.014470895026108543\n",
      "Lead Time  6 hours  | Observable  v10 | Mean CRPS  0.016108815 | Std CRPS  0.019013513\n",
      "Lead Time  12 hours  | Observable  z | Mean RMSD  231.9722468068148 | Std RMSD  14.932544445086654\n",
      "Lead Time  12 hours  | Observable  z | Mean ACC  0.9751015917872143 | Std ACC  0.007924596247338564\n",
      "Lead Time  12 hours  | Observable  z | Mean CRPS  0.009064386 | Std CRPS  0.008982475\n",
      "Lead Time  12 hours  | Observable  t | Mean RMSD  2.1560883421836152 | Std RMSD  0.09402578471857059\n",
      "Lead Time  12 hours  | Observable  t | Mean ACC  0.9329714744944899 | Std ACC  0.030396207159734533\n",
      "Lead Time  12 hours  | Observable  t | Mean CRPS  0.014165696 | Std CRPS  0.012747425\n",
      "Lead Time  12 hours  | Observable  t2m | Mean RMSD  3.426730662306103 | Std RMSD  0.23116209952899247\n",
      "Lead Time  12 hours  | Observable  t2m | Mean ACC  0.790900958279772 | Std ACC  0.131008586537876\n",
      "Lead Time  12 hours  | Observable  t2m | Mean CRPS  0.013270729 | Std CRPS  0.015833123\n",
      "Lead Time  12 hours  | Observable  u10 | Mean RMSD  2.1942632303772958 | Std RMSD  0.09796826120768203\n",
      "Lead Time  12 hours  | Observable  u10 | Mean ACC  0.8521775524913462 | Std ACC  0.01814818021771513\n",
      "Lead Time  12 hours  | Observable  u10 | Mean CRPS  0.018862363 | Std CRPS  0.020845117\n",
      "Lead Time  12 hours  | Observable  v10 | Mean RMSD  2.245318155691296 | Std RMSD  0.12645038938858183\n",
      "Lead Time  12 hours  | Observable  v10 | Mean ACC  0.8427948730117523 | Std ACC  0.01996804833840514\n",
      "Lead Time  12 hours  | Observable  v10 | Mean CRPS  0.020109171 | Std CRPS  0.021656346\n",
      "Lead Time  18 hours  | Observable  z | Mean RMSD  285.3919725891941 | Std RMSD  21.341351514070077\n",
      "Lead Time  18 hours  | Observable  z | Mean ACC  0.96091613355762 | Std ACC  0.01250392878527936\n",
      "Lead Time  18 hours  | Observable  z | Mean CRPS  0.011548763 | Std CRPS  0.012333463\n",
      "Lead Time  18 hours  | Observable  t | Mean RMSD  2.2967953871450493 | Std RMSD  0.11462049547398655\n",
      "Lead Time  18 hours  | Observable  t | Mean ACC  0.921286133403001 | Std ACC  0.03549542853935131\n",
      "Lead Time  18 hours  | Observable  t | Mean CRPS  0.01574482 | Std CRPS  0.014498977\n",
      "Lead Time  18 hours  | Observable  t2m | Mean RMSD  2.5945915157225827 | Std RMSD  0.19732708939248814\n",
      "Lead Time  18 hours  | Observable  t2m | Mean ACC  0.8816472382180889 | Std ACC  0.07029508559933174\n",
      "Lead Time  18 hours  | Observable  t2m | Mean CRPS  0.011639066 | Std CRPS  0.011427371\n",
      "Lead Time  18 hours  | Observable  u10 | Mean RMSD  2.3947764153347197 | Std RMSD  0.1100583764846799\n",
      "Lead Time  18 hours  | Observable  u10 | Mean ACC  0.8213978155819205 | Std ACC  0.022741727275772325\n",
      "Lead Time  18 hours  | Observable  u10 | Mean CRPS  0.021641552 | Std CRPS  0.023710014\n",
      "Lead Time  18 hours  | Observable  v10 | Mean RMSD  2.431763735942676 | Std RMSD  0.1548649857759237\n",
      "Lead Time  18 hours  | Observable  v10 | Mean ACC  0.8129103735181158 | Std ACC  0.025620669828046266\n",
      "Lead Time  18 hours  | Observable  v10 | Mean CRPS  0.022782782 | Std CRPS  0.024363497\n",
      "Lead Time  24 hours  | Observable  z | Mean RMSD  353.49764469633186 | Std RMSD  26.961717286792005\n",
      "Lead Time  24 hours  | Observable  z | Mean ACC  0.9388062778255003 | Std ACC  0.01945964623239368\n",
      "Lead Time  24 hours  | Observable  z | Mean CRPS  0.01496065 | Std CRPS  0.015812196\n",
      "Lead Time  24 hours  | Observable  t | Mean RMSD  2.5119245275163915 | Std RMSD  0.1388482478875974\n",
      "Lead Time  24 hours  | Observable  t | Mean ACC  0.8982862557386907 | Std ACC  0.045798807556773485\n",
      "Lead Time  24 hours  | Observable  t | Mean CRPS  0.017698565 | Std CRPS  0.016615525\n",
      "Lead Time  24 hours  | Observable  t2m | Mean RMSD  2.6271708040467816 | Std RMSD  0.3589058011684817\n",
      "Lead Time  24 hours  | Observable  t2m | Mean ACC  0.8779217688635728 | Std ACC  0.07869042413047478\n",
      "Lead Time  24 hours  | Observable  t2m | Mean CRPS  0.0123911705 | Std CRPS  0.01234888\n",
      "Lead Time  24 hours  | Observable  u10 | Mean RMSD  2.6318475432631487 | Std RMSD  0.13239388788372553\n",
      "Lead Time  24 hours  | Observable  u10 | Mean ACC  0.7756639416553145 | Std ACC  0.029206890566168493\n",
      "Lead Time  24 hours  | Observable  u10 | Mean CRPS  0.024753971 | Std CRPS  0.028829165\n",
      "Lead Time  24 hours  | Observable  v10 | Mean RMSD  2.652854151620015 | Std RMSD  0.18325530973973989\n",
      "Lead Time  24 hours  | Observable  v10 | Mean ACC  0.7679887532221812 | Std ACC  0.03443245039937488\n",
      "Lead Time  24 hours  | Observable  v10 | Mean CRPS  0.025752522 | Std CRPS  0.028131522\n",
      "Lead Time  30 hours  | Observable  z | Mean RMSD  403.9543487633573 | Std RMSD  34.21816706541744\n",
      "Lead Time  30 hours  | Observable  z | Mean ACC  0.9196929021668724 | Std ACC  0.025953217431534118\n",
      "Lead Time  30 hours  | Observable  z | Mean CRPS  0.017200308 | Std CRPS  0.019574001\n",
      "Lead Time  30 hours  | Observable  t | Mean RMSD  2.770163243372725 | Std RMSD  0.16650071923909604\n",
      "Lead Time  30 hours  | Observable  t | Mean ACC  0.8699085814403104 | Std ACC  0.05952205759569024\n",
      "Lead Time  30 hours  | Observable  t | Mean CRPS  0.019884242 | Std CRPS  0.018678656\n",
      "Lead Time  30 hours  | Observable  t2m | Mean RMSD  3.597373999482292 | Std RMSD  0.3646437059298923\n",
      "Lead Time  30 hours  | Observable  t2m | Mean ACC  0.754292324561154 | Std ACC  0.15085636136044395\n",
      "Lead Time  30 hours  | Observable  t2m | Mean CRPS  0.016576285 | Std CRPS  0.017658252\n",
      "Lead Time  30 hours  | Observable  u10 | Mean RMSD  2.952600904893087 | Std RMSD  0.16807850114148365\n",
      "Lead Time  30 hours  | Observable  u10 | Mean ACC  0.712211351867684 | Std ACC  0.04189043368201979\n",
      "Lead Time  30 hours  | Observable  u10 | Mean CRPS  0.028541096 | Std CRPS  0.03643628\n",
      "Lead Time  30 hours  | Observable  v10 | Mean RMSD  3.018066581202039 | Std RMSD  0.22530480266494682\n",
      "Lead Time  30 hours  | Observable  v10 | Mean ACC  0.6959650705470121 | Std ACC  0.04603773320086729\n",
      "Lead Time  30 hours  | Observable  v10 | Mean CRPS  0.030196384 | Std CRPS  0.038573645\n",
      "Lead Time  36 hours  | Observable  z | Mean RMSD  nan | Std RMSD  nan\n",
      "Lead Time  36 hours  | Observable  z | Mean ACC  nan | Std ACC  nan\n",
      "Lead Time  36 hours  | Observable  z | Mean CRPS  nan | Std CRPS  nan\n",
      "Lead Time  36 hours  | Observable  t | Mean RMSD  nan | Std RMSD  nan\n",
      "Lead Time  36 hours  | Observable  t | Mean ACC  nan | Std ACC  nan\n",
      "Lead Time  36 hours  | Observable  t | Mean CRPS  nan | Std CRPS  nan\n",
      "Lead Time  36 hours  | Observable  t2m | Mean RMSD  nan | Std RMSD  nan\n",
      "Lead Time  36 hours  | Observable  t2m | Mean ACC  nan | Std ACC  nan\n",
      "Lead Time  36 hours  | Observable  t2m | Mean CRPS  nan | Std CRPS  nan\n",
      "Lead Time  36 hours  | Observable  u10 | Mean RMSD  nan | Std RMSD  nan\n",
      "Lead Time  36 hours  | Observable  u10 | Mean ACC  nan | Std ACC  nan\n",
      "Lead Time  36 hours  | Observable  u10 | Mean CRPS  nan | Std CRPS  nan\n",
      "Lead Time  36 hours  | Observable  v10 | Mean RMSD  nan | Std RMSD  nan\n",
      "Lead Time  36 hours  | Observable  v10 | Mean ACC  nan | Std ACC  nan\n",
      "Lead Time  36 hours  | Observable  v10 | Mean CRPS  nan | Std CRPS  nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for t_idx in range(6):\n",
    "    for idx, lev in enumerate(levels):\n",
    "        print(\"Lead Time \",(t_idx+1)*6, \"hours \",\"| Observable \",lev, \"| Mean RMSD \", np.mean(Lead_RMSD_arr[lev][t_idx]), \"| Std RMSD \", np.std(Lead_RMSD_arr[lev][t_idx]))\n",
    "        print(\"Lead Time \",(t_idx+1)*6, \"hours \",\"| Observable \",lev, \"| Mean ACC \", np.mean(Lead_ACC[lev][t_idx]), \"| Std ACC \", np.std(Lead_ACC[lev][t_idx]))\n",
    "        print(\"Lead Time \",(t_idx+1)*6, \"hours \",\"| Observable \",lev, \"| Mean CRPS \", np.mean(Lead_CRPS[lev][t_idx]), \"| Std CRPS \", np.std(Lead_CRPS[lev][t_idx]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
